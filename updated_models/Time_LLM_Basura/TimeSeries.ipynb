{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a325c881-b5c6-4902-bc26-a59f23ee70d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from timefeatures import time_features\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ace1d06-b143-498a-844b-373d10c19663",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeLLMDataset(Dataset):\n",
    "    def __init__(self, root_path, flag='train', size=None,\n",
    "                 features='M', data_path='your_dataset.csv',\n",
    "                 target='target_column', scale=True, timeenc=0, freq='h', percent=100):\n",
    "        if size is None:\n",
    "            self.seq_len = 384  # Example sequence length\n",
    "            self.label_len = 96  # Example label length\n",
    "            self.pred_len = 96  # Example prediction length\n",
    "        else:\n",
    "            self.seq_len = size[0]\n",
    "            self.label_len = size[1]\n",
    "            self.pred_len = size[2]\n",
    "\n",
    "        # Initialize parameters\n",
    "        assert flag in ['train', 'test', 'val']\n",
    "        type_map = {'train': 0, 'val': 1, 'test': 2}\n",
    "        self.set_type = type_map[flag]\n",
    "\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.scale = scale\n",
    "        self.timeenc = timeenc\n",
    "        self.freq = freq\n",
    "        self.percent = percent\n",
    "\n",
    "        self.root_path = root_path\n",
    "        self.data_path = data_path\n",
    "        self.__read_data__()\n",
    "\n",
    "        self.enc_in = self.data_x.shape[-1]\n",
    "        self.tot_len = len(self.data_x) - self.seq_len - self.pred_len + 1\n",
    "\n",
    "    def __read_data__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        df_raw = pd.read_csv(os.path.join(self.root_path, self.data_path))\n",
    "\n",
    "        cols = list(df_raw.columns)\n",
    "        #print(cols)\n",
    "        #cols.remove(self.target)\n",
    "        cols.remove('Date')\n",
    "        df_raw = df_raw[['Date'] + cols] #+ [self.target]]\n",
    "        #print(len(df_raw))\n",
    "\n",
    "        num_train = int(len(df_raw) * 0.7)\n",
    "        num_test = int(len(df_raw) * 0.2)\n",
    "        num_vali = len(df_raw) - num_train - num_test\n",
    "        border1s = [0, num_train - self.seq_len, len(df_raw) - num_test - self.seq_len]\n",
    "        border2s = [num_train, num_train + num_vali, len(df_raw)]\n",
    "        border1 = border1s[self.set_type]\n",
    "        border2 = border2s[self.set_type]\n",
    "        #print(\"border1: \", border1)\n",
    "        #print(\"border2: \", border2)\n",
    "        #print(num_train,num_test,num_vali)\n",
    "\n",
    "        if self.set_type == 0:\n",
    "            border2 = (border2 - self.seq_len) * self.percent // 100 + self.seq_len\n",
    "\n",
    "        if self.features == 'M' or self.features == 'MS':\n",
    "            cols_data = df_raw.columns[1:]\n",
    "            #print(cols_data)\n",
    "            df_data = df_raw[cols_data]\n",
    "            #print('data',df_data)\n",
    "        elif self.features == 'S':\n",
    "            df_data = df_raw[[self.target]]\n",
    "\n",
    "        if self.scale:\n",
    "            train_data = df_data[border1s[0]:border2s[0]]\n",
    "            #print(\"train\", train_data)\n",
    "            self.scaler.fit(train_data.values)\n",
    "            data = self.scaler.transform(df_data.values)\n",
    "            #print(data)\n",
    "        else:\n",
    "            data = df_data.values\n",
    "\n",
    "        df_stamp = df_raw[['Date']][border1:border2]\n",
    "        df_stamp['Date'] = pd.to_datetime(df_stamp.Date)\n",
    "        #print(self.timeenc)\n",
    "        if self.timeenc == 0:\n",
    "            df_stamp['month'] = df_stamp.Date.apply(lambda row: row.month, 1)\n",
    "            df_stamp['day'] = df_stamp.Date.apply(lambda row: row.day, 1)\n",
    "            df_stamp['weekday'] = df_stamp.Date.apply(lambda row: row.weekday(), 1)\n",
    "            df_stamp['hour'] = df_stamp.Date.apply(lambda row: row.hour, 1)\n",
    "            data_stamp = df_stamp.drop(['Date'], 1).values\n",
    "            #print('data',data_stamp)\n",
    "        elif self.timeenc == 1:\n",
    "            data_stamp = time_features(pd.to_datetime(df_stamp['Date'].values), freq=self.freq)\n",
    "            data_stamp = data_stamp.transpose(1, 0)\n",
    "            #print(data_stamp)\n",
    "\n",
    "        self.data_x = data[border1:border2]\n",
    "        #print(len(self.data_x))\n",
    "        self.data_y = data[border1:border2]\n",
    "        #print(len(self.data_x))\n",
    "        self.data_stamp = data_stamp\n",
    "        print(f\"data_x shape: {self.data_x.shape}\")\n",
    "        print(f\"data_y shape: {self.data_y.shape}\")\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        feat_id = index // self.tot_len\n",
    "        #print(\"hi\",feat_id)\n",
    "        s_begin = index % self.tot_len\n",
    "\n",
    "        s_end = s_begin + self.seq_len\n",
    "        r_begin = s_end - self.label_len\n",
    "        r_end = r_begin + self.label_len + self.pred_len\n",
    "        seq_x = self.data_x[s_begin:s_end, feat_id:feat_id + 1]\n",
    "        seq_y = self.data_y[r_begin:r_end, feat_id:feat_id + 1]\n",
    "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
    "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
    "\n",
    "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.data_x) - self.seq_len - self.pred_len + 1) * self.enc_in\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        return self.scaler.inverse_transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e312aaf-0489-4beb-a242-27e8b4d86a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_provider(args, flag):\n",
    "    # Set time encoding based on the 'embed' argument\n",
    "    #print(args.embed)\n",
    "    timeenc = 0 if args.embed != 'timeF' else 1\n",
    "    #print(timeenc)\n",
    "    \n",
    "    # Determine whether to shuffle data and whether to drop the last incomplete batch\n",
    "    if flag == 'test':\n",
    "        shuffle_flag = False\n",
    "        drop_last = True\n",
    "    else:\n",
    "        shuffle_flag = True\n",
    "        drop_last = True\n",
    "\n",
    "    # Set batch size and frequency\n",
    "    batch_size = args.batch_size\n",
    "    freq = args.freq\n",
    "\n",
    "    # Initialize the custom dataset\n",
    "    data_set = TimeLLMDataset(\n",
    "        root_path=args.root_path,\n",
    "        data_path=args.data_path,\n",
    "        flag=flag,\n",
    "        size=[args.seq_len, args.label_len, args.pred_len],\n",
    "        features=args.features,\n",
    "        target=args.target,\n",
    "        timeenc=timeenc,\n",
    "        freq=freq,\n",
    "        percent=args.percent\n",
    "    ) #seasonal_patterns=args.seasonal_patterns\n",
    "    \n",
    "    # Create DataLoader\n",
    "    data_loader = DataLoader(\n",
    "        data_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle_flag,\n",
    "        num_workers=args.num_workers,\n",
    "        drop_last=drop_last\n",
    "    )\n",
    "\n",
    "    return data_set, data_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "831349b0-5f87-40ac-b417-cd6864d85b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse \n",
    "args = argparse.Namespace(\n",
    "    root_path='./',  # Assuming the file is in the current directory\n",
    "    data_path='NVDA.csv',  # Your CSV file\n",
    "    seq_len=384,\n",
    "    label_len=96,\n",
    "    pred_len=96,\n",
    "    features='M',  # 'M' for multivariate, 'S' for univariate\n",
    "    target= None,  # Replace with the actual name of the target column in your CSV\n",
    "    embed='timeF',  # Use 'timeF' for time feature encoding\n",
    "    scale=True,\n",
    "    percent=100,\n",
    "    num_workers=0,\n",
    "    batch_size=32,\n",
    "    freq='d'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff2f0d15-bc1f-4ec1-9bcc-b897b2e51f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_x shape: (870, 6)\n",
      "data_y shape: (870, 6)\n",
      "data_x shape: (509, 6)\n",
      "data_y shape: (509, 6)\n",
      "data_x shape: (632, 6)\n",
      "data_y shape: (632, 6)\n"
     ]
    }
   ],
   "source": [
    "train_data, train_loader = data_provider(args, flag='train')\n",
    "val_data, val_loader = data_provider(args, flag='val')\n",
    "test_data, test_loader = data_provider(args, flag='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "864411f5-dcb2-4683-a05d-03e40223d1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sequence (seq_x): torch.Size([32, 384, 1])\n",
      "Target Sequence (seq_y): torch.Size([32, 192, 1])\n",
      "Input Time Markers (seq_x_mark): torch.Size([32, 384, 3])\n",
      "Target Time Markers (seq_y_mark): torch.Size([32, 192, 3])\n",
      "First Batch Input Data:\n",
      " tensor([[-2.7608e-01],\n",
      "        [-2.7009e-01],\n",
      "        [-2.2698e-01],\n",
      "        [-2.1943e-01],\n",
      "        [-2.3665e-01],\n",
      "        [-2.2224e-01],\n",
      "        [-2.3234e-01],\n",
      "        [-2.2355e-01],\n",
      "        [-2.3143e-01],\n",
      "        [-2.7068e-01],\n",
      "        [-2.7294e-01],\n",
      "        [-2.8662e-01],\n",
      "        [-2.8031e-01],\n",
      "        [-2.5076e-01],\n",
      "        [-2.6400e-01],\n",
      "        [-2.5547e-01],\n",
      "        [-2.1297e-01],\n",
      "        [-3.2827e-01],\n",
      "        [-2.2184e-01],\n",
      "        [-2.3165e-01],\n",
      "        [-1.8135e-01],\n",
      "        [-2.0130e-01],\n",
      "        [-1.9444e-01],\n",
      "        [-2.4281e-01],\n",
      "        [-2.9253e-01],\n",
      "        [-2.6834e-01],\n",
      "        [-2.1866e-01],\n",
      "        [-1.4545e-01],\n",
      "        [-1.6807e-01],\n",
      "        [-1.7671e-01],\n",
      "        [-2.0852e-01],\n",
      "        [-2.8403e-01],\n",
      "        [-2.6459e-01],\n",
      "        [-2.7352e-01],\n",
      "        [-2.3745e-01],\n",
      "        [-1.9079e-01],\n",
      "        [-1.9462e-01],\n",
      "        [-1.7511e-01],\n",
      "        [-1.8580e-01],\n",
      "        [-6.2104e-02],\n",
      "        [-8.7711e-02],\n",
      "        [-1.4612e-02],\n",
      "        [ 5.6372e-02],\n",
      "        [ 1.4132e-02],\n",
      "        [ 6.7972e-02],\n",
      "        [ 6.0706e-03],\n",
      "        [-5.1641e-03],\n",
      "        [ 9.0618e-03],\n",
      "        [-7.4214e-02],\n",
      "        [-1.0540e-01],\n",
      "        [-5.3313e-02],\n",
      "        [-2.2716e-01],\n",
      "        [-1.6778e-01],\n",
      "        [-1.4921e-01],\n",
      "        [-2.1275e-01],\n",
      "        [-3.0052e-01],\n",
      "        [-3.6391e-01],\n",
      "        [-3.5060e-01],\n",
      "        [-4.7728e-01],\n",
      "        [-3.4140e-01],\n",
      "        [-3.4899e-01],\n",
      "        [-2.7232e-01],\n",
      "        [-2.9239e-01],\n",
      "        [-2.4346e-01],\n",
      "        [-2.2886e-01],\n",
      "        [-2.2157e-01],\n",
      "        [-3.1188e-01],\n",
      "        [-2.9389e-01],\n",
      "        [-2.4419e-01],\n",
      "        [-2.6105e-01],\n",
      "        [-3.2348e-01],\n",
      "        [-3.3921e-01],\n",
      "        [-2.9484e-01],\n",
      "        [-2.7893e-01],\n",
      "        [-2.9009e-01],\n",
      "        [-2.2054e-01],\n",
      "        [-1.5289e-01],\n",
      "        [-1.2724e-01],\n",
      "        [-1.4563e-01],\n",
      "        [-1.0447e-01],\n",
      "        [-7.9147e-02],\n",
      "        [-6.7033e-02],\n",
      "        [ 5.1047e-02],\n",
      "        [ 1.1972e-01],\n",
      "        [ 6.0971e-02],\n",
      "        [ 1.8653e-01],\n",
      "        [ 1.5373e-01],\n",
      "        [ 7.3341e-02],\n",
      "        [ 4.5537e-02],\n",
      "        [ 7.3159e-02],\n",
      "        [-1.3155e-03],\n",
      "        [ 5.9257e-02],\n",
      "        [ 9.0309e-02],\n",
      "        [ 7.6260e-02],\n",
      "        [ 6.0935e-02],\n",
      "        [ 6.7941e-02],\n",
      "        [ 2.1928e-02],\n",
      "        [-3.2863e-03],\n",
      "        [-7.4148e-02],\n",
      "        [-5.8494e-02],\n",
      "        [-4.9080e-02],\n",
      "        [-6.8621e-03],\n",
      "        [-8.6627e-02],\n",
      "        [-8.0716e-02],\n",
      "        [-1.6066e-01],\n",
      "        [-1.7427e-01],\n",
      "        [-8.9948e-02],\n",
      "        [-1.0126e-01],\n",
      "        [-1.2312e-01],\n",
      "        [-1.1582e-01],\n",
      "        [-3.6017e-02],\n",
      "        [ 1.9337e-02],\n",
      "        [ 1.0987e-01],\n",
      "        [ 1.1509e-01],\n",
      "        [ 1.2271e-01],\n",
      "        [ 9.1769e-02],\n",
      "        [ 2.0219e-01],\n",
      "        [ 2.0510e-01],\n",
      "        [ 2.8009e-01],\n",
      "        [ 3.0804e-01],\n",
      "        [ 3.9685e-01],\n",
      "        [ 4.0280e-01],\n",
      "        [ 3.7916e-01],\n",
      "        [ 3.6533e-01],\n",
      "        [ 3.7507e-01],\n",
      "        [ 4.3350e-01],\n",
      "        [ 4.6175e-01],\n",
      "        [ 4.2814e-01],\n",
      "        [ 4.3131e-01],\n",
      "        [ 5.5497e-01],\n",
      "        [ 5.5227e-01],\n",
      "        [ 5.2139e-01],\n",
      "        [ 5.8847e-01],\n",
      "        [ 6.1336e-01],\n",
      "        [ 6.3501e-01],\n",
      "        [ 6.0953e-01],\n",
      "        [ 7.4881e-01],\n",
      "        [ 7.5490e-01],\n",
      "        [ 7.5136e-01],\n",
      "        [ 7.8195e-01],\n",
      "        [ 8.2209e-01],\n",
      "        [ 8.5297e-01],\n",
      "        [ 8.0527e-01],\n",
      "        [ 7.3680e-01],\n",
      "        [ 7.5833e-01],\n",
      "        [ 8.2582e-01],\n",
      "        [ 7.8749e-01],\n",
      "        [ 7.2786e-01],\n",
      "        [ 6.0008e-01],\n",
      "        [ 4.8252e-01],\n",
      "        [ 5.7285e-01],\n",
      "        [ 5.4836e-01],\n",
      "        [ 6.6486e-01],\n",
      "        [ 6.9172e-01],\n",
      "        [ 6.8647e-01],\n",
      "        [ 6.4793e-01],\n",
      "        [ 6.3537e-01],\n",
      "        [ 6.7844e-01],\n",
      "        [ 7.0165e-01],\n",
      "        [ 6.7786e-01],\n",
      "        [ 7.1450e-01],\n",
      "        [ 7.2399e-01],\n",
      "        [ 7.9100e-01],\n",
      "        [ 8.4399e-01],\n",
      "        [ 8.0443e-01],\n",
      "        [ 7.9406e-01],\n",
      "        [ 7.4165e-01],\n",
      "        [ 7.0705e-01],\n",
      "        [ 7.3713e-01],\n",
      "        [ 7.7844e-01],\n",
      "        [ 7.4370e-01],\n",
      "        [ 6.7187e-01],\n",
      "        [ 6.1084e-01],\n",
      "        [ 7.2151e-01],\n",
      "        [ 8.7012e-01],\n",
      "        [ 1.0368e+00],\n",
      "        [ 1.0128e+00],\n",
      "        [ 1.0741e+00],\n",
      "        [ 1.0529e+00],\n",
      "        [ 1.1358e+00],\n",
      "        [ 1.1434e+00],\n",
      "        [ 1.0998e+00],\n",
      "        [ 1.1079e+00],\n",
      "        [ 1.1014e+00],\n",
      "        [ 1.1666e+00],\n",
      "        [ 1.1402e+00],\n",
      "        [ 1.0930e+00],\n",
      "        [ 1.0694e+00],\n",
      "        [ 1.1133e+00],\n",
      "        [ 1.0657e+00],\n",
      "        [ 1.0789e+00],\n",
      "        [ 1.0933e+00],\n",
      "        [ 1.0789e+00],\n",
      "        [ 1.0289e+00],\n",
      "        [ 9.1403e-01],\n",
      "        [ 9.3345e-01],\n",
      "        [ 1.0349e+00],\n",
      "        [ 1.1139e+00],\n",
      "        [ 1.0554e+00],\n",
      "        [ 9.9390e-01],\n",
      "        [ 8.5358e-01],\n",
      "        [ 8.2700e-01],\n",
      "        [ 8.5606e-01],\n",
      "        [ 8.5985e-01],\n",
      "        [ 7.1238e-01],\n",
      "        [ 8.1736e-01],\n",
      "        [ 8.5372e-01],\n",
      "        [ 9.0848e-01],\n",
      "        [ 8.7285e-01],\n",
      "        [ 8.5299e-01],\n",
      "        [ 8.4949e-01],\n",
      "        [ 8.8862e-01],\n",
      "        [ 1.0065e+00],\n",
      "        [ 1.0234e+00],\n",
      "        [ 1.0760e+00],\n",
      "        [ 1.0859e+00],\n",
      "        [ 1.0586e+00],\n",
      "        [ 1.1446e+00],\n",
      "        [ 1.1496e+00],\n",
      "        [ 1.2138e+00],\n",
      "        [ 1.4403e+00],\n",
      "        [ 1.4014e+00],\n",
      "        [ 1.4730e+00],\n",
      "        [ 1.5644e+00],\n",
      "        [ 1.6023e+00],\n",
      "        [ 1.6862e+00],\n",
      "        [ 1.7149e+00],\n",
      "        [ 2.1826e+00],\n",
      "        [ 2.1755e+00],\n",
      "        [ 2.3291e+00],\n",
      "        [ 2.3076e+00],\n",
      "        [ 2.1327e+00],\n",
      "        [ 2.2686e+00],\n",
      "        [ 2.2686e+00],\n",
      "        [ 2.2153e+00],\n",
      "        [ 2.2413e+00],\n",
      "        [ 2.1038e+00],\n",
      "        [ 2.4563e+00],\n",
      "        [ 2.6475e+00],\n",
      "        [ 2.4973e+00],\n",
      "        [ 2.4666e+00],\n",
      "        [ 2.6021e+00],\n",
      "        [ 2.4311e+00],\n",
      "        [ 2.7046e+00],\n",
      "        [ 2.6024e+00],\n",
      "        [ 2.4218e+00],\n",
      "        [ 2.5227e+00],\n",
      "        [ 2.3134e+00],\n",
      "        [ 2.2176e+00],\n",
      "        [ 2.5666e+00],\n",
      "        [ 2.4789e+00],\n",
      "        [ 2.2838e+00],\n",
      "        [ 2.2411e+00],\n",
      "        [ 1.9437e+00],\n",
      "        [ 1.9694e+00],\n",
      "        [ 2.2792e+00],\n",
      "        [ 1.9767e+00],\n",
      "        [ 1.8911e+00],\n",
      "        [ 1.8791e+00],\n",
      "        [ 2.0771e+00],\n",
      "        [ 2.1246e+00],\n",
      "        [ 2.1596e+00],\n",
      "        [ 2.3502e+00],\n",
      "        [ 2.2592e+00],\n",
      "        [ 2.2124e+00],\n",
      "        [ 2.1518e+00],\n",
      "        [ 2.1262e+00],\n",
      "        [ 2.2299e+00],\n",
      "        [ 2.1085e+00],\n",
      "        [ 1.8623e+00],\n",
      "        [ 1.9461e+00],\n",
      "        [ 1.8102e+00],\n",
      "        [ 1.8325e+00],\n",
      "        [ 1.8934e+00],\n",
      "        [ 1.9200e+00],\n",
      "        [ 1.7120e+00],\n",
      "        [ 1.7656e+00],\n",
      "        [ 1.6139e+00],\n",
      "        [ 1.4918e+00],\n",
      "        [ 1.3579e+00],\n",
      "        [ 1.2446e+00],\n",
      "        [ 1.2443e+00],\n",
      "        [ 1.0913e+00],\n",
      "        [ 1.1567e+00],\n",
      "        [ 1.0358e+00],\n",
      "        [ 1.1666e+00],\n",
      "        [ 1.4070e+00],\n",
      "        [ 1.4292e+00],\n",
      "        [ 1.5174e+00],\n",
      "        [ 1.3284e+00],\n",
      "        [ 1.3826e+00],\n",
      "        [ 1.4423e+00],\n",
      "        [ 1.4978e+00],\n",
      "        [ 1.7310e+00],\n",
      "        [ 1.6024e+00],\n",
      "        [ 1.3286e+00],\n",
      "        [ 1.3750e+00],\n",
      "        [ 1.7004e+00],\n",
      "        [ 1.7027e+00],\n",
      "        [ 1.4100e+00],\n",
      "        [ 1.2837e+00],\n",
      "        [ 1.2469e+00],\n",
      "        [ 1.1005e+00],\n",
      "        [ 1.2992e+00],\n",
      "        [ 1.3589e+00],\n",
      "        [ 1.3922e+00],\n",
      "        [ 1.2596e+00],\n",
      "        [ 1.3687e+00],\n",
      "        [ 1.2948e+00],\n",
      "        [ 1.1812e+00],\n",
      "        [ 9.4984e-01],\n",
      "        [ 9.7350e-01],\n",
      "        [ 1.1926e+00],\n",
      "        [ 1.1406e+00],\n",
      "        [ 1.0591e+00],\n",
      "        [ 9.4662e-01],\n",
      "        [ 1.1866e+00],\n",
      "        [ 1.4090e+00],\n",
      "        [ 1.4485e+00],\n",
      "        [ 1.6949e+00],\n",
      "        [ 1.7359e+00],\n",
      "        [ 1.7053e+00],\n",
      "        [ 1.5753e+00],\n",
      "        [ 1.9427e+00],\n",
      "        [ 1.8759e+00],\n",
      "        [ 1.9528e+00],\n",
      "        [ 2.0167e+00],\n",
      "        [ 1.8756e+00],\n",
      "        [ 1.8166e+00],\n",
      "        [ 1.7327e+00],\n",
      "        [ 1.8274e+00],\n",
      "        [ 1.6186e+00],\n",
      "        [ 1.3960e+00],\n",
      "        [ 1.3670e+00],\n",
      "        [ 1.2079e+00],\n",
      "        [ 1.0324e+00],\n",
      "        [ 9.7204e-01],\n",
      "        [ 1.0741e+00],\n",
      "        [ 9.3611e-01],\n",
      "        [ 1.0128e+00],\n",
      "        [ 1.0734e+00],\n",
      "        [ 9.6883e-01],\n",
      "        [ 7.7909e-01],\n",
      "        [ 6.8153e-01],\n",
      "        [ 7.3805e-01],\n",
      "        [ 5.7534e-01],\n",
      "        [ 5.2086e-01],\n",
      "        [ 7.2052e-01],\n",
      "        [ 5.4014e-01],\n",
      "        [ 6.8416e-01],\n",
      "        [ 6.9423e-01],\n",
      "        [ 8.0115e-01],\n",
      "        [ 5.8352e-01],\n",
      "        [ 5.5884e-01],\n",
      "        [ 3.0689e-01],\n",
      "        [ 4.0109e-01],\n",
      "        [ 2.6015e-01],\n",
      "        [ 1.9369e-01],\n",
      "        [ 4.1731e-01],\n",
      "        [ 3.5275e-01],\n",
      "        [ 4.8610e-01],\n",
      "        [ 3.0513e-01],\n",
      "        [ 3.3230e-01],\n",
      "        [ 2.6950e-01],\n",
      "        [ 2.9929e-01],\n",
      "        [ 1.9062e-01],\n",
      "        [ 3.1054e-01],\n",
      "        [ 4.3849e-01],\n",
      "        [ 5.7870e-01],\n",
      "        [ 5.5840e-01],\n",
      "        [ 5.0699e-01],\n",
      "        [ 6.9277e-01],\n",
      "        [ 5.6541e-01],\n",
      "        [ 5.7505e-01],\n",
      "        [ 5.9550e-01],\n",
      "        [ 5.5547e-01],\n",
      "        [ 4.6782e-01],\n",
      "        [ 3.1092e-01],\n",
      "        [ 1.1705e-01],\n",
      "        [ 1.4467e-01],\n",
      "        [ 2.4561e-01],\n",
      "        [ 1.1033e-01],\n",
      "        [ 1.5109e-01],\n",
      "        [ 2.5131e-01]], dtype=torch.float64)\n",
      "First Batch Target Data:\n",
      " tensor([[ 1.5174],\n",
      "        [ 1.3284],\n",
      "        [ 1.3826],\n",
      "        [ 1.4423],\n",
      "        [ 1.4978],\n",
      "        [ 1.7310],\n",
      "        [ 1.6024],\n",
      "        [ 1.3286],\n",
      "        [ 1.3750],\n",
      "        [ 1.7004],\n",
      "        [ 1.7027],\n",
      "        [ 1.4100],\n",
      "        [ 1.2837],\n",
      "        [ 1.2469],\n",
      "        [ 1.1005],\n",
      "        [ 1.2992],\n",
      "        [ 1.3589],\n",
      "        [ 1.3922],\n",
      "        [ 1.2596],\n",
      "        [ 1.3687],\n",
      "        [ 1.2948],\n",
      "        [ 1.1812],\n",
      "        [ 0.9498],\n",
      "        [ 0.9735],\n",
      "        [ 1.1926],\n",
      "        [ 1.1406],\n",
      "        [ 1.0591],\n",
      "        [ 0.9466],\n",
      "        [ 1.1866],\n",
      "        [ 1.4090],\n",
      "        [ 1.4485],\n",
      "        [ 1.6949],\n",
      "        [ 1.7359],\n",
      "        [ 1.7053],\n",
      "        [ 1.5753],\n",
      "        [ 1.9427],\n",
      "        [ 1.8759],\n",
      "        [ 1.9528],\n",
      "        [ 2.0167],\n",
      "        [ 1.8756],\n",
      "        [ 1.8166],\n",
      "        [ 1.7327],\n",
      "        [ 1.8274],\n",
      "        [ 1.6186],\n",
      "        [ 1.3960],\n",
      "        [ 1.3670],\n",
      "        [ 1.2079],\n",
      "        [ 1.0324],\n",
      "        [ 0.9720],\n",
      "        [ 1.0741],\n",
      "        [ 0.9361],\n",
      "        [ 1.0128],\n",
      "        [ 1.0734],\n",
      "        [ 0.9688],\n",
      "        [ 0.7791],\n",
      "        [ 0.6815],\n",
      "        [ 0.7381],\n",
      "        [ 0.5753],\n",
      "        [ 0.5209],\n",
      "        [ 0.7205],\n",
      "        [ 0.5401],\n",
      "        [ 0.6842],\n",
      "        [ 0.6942],\n",
      "        [ 0.8011],\n",
      "        [ 0.5835],\n",
      "        [ 0.5588],\n",
      "        [ 0.3069],\n",
      "        [ 0.4011],\n",
      "        [ 0.2601],\n",
      "        [ 0.1937],\n",
      "        [ 0.4173],\n",
      "        [ 0.3527],\n",
      "        [ 0.4861],\n",
      "        [ 0.3051],\n",
      "        [ 0.3323],\n",
      "        [ 0.2695],\n",
      "        [ 0.2993],\n",
      "        [ 0.1906],\n",
      "        [ 0.3105],\n",
      "        [ 0.4385],\n",
      "        [ 0.5787],\n",
      "        [ 0.5584],\n",
      "        [ 0.5070],\n",
      "        [ 0.6928],\n",
      "        [ 0.5654],\n",
      "        [ 0.5751],\n",
      "        [ 0.5955],\n",
      "        [ 0.5555],\n",
      "        [ 0.4678],\n",
      "        [ 0.3109],\n",
      "        [ 0.1171],\n",
      "        [ 0.1447],\n",
      "        [ 0.2456],\n",
      "        [ 0.1103],\n",
      "        [ 0.1511],\n",
      "        [ 0.2513],\n",
      "        [ 0.2212],\n",
      "        [ 0.2015],\n",
      "        [ 0.3331],\n",
      "        [ 0.2956],\n",
      "        [ 0.1660],\n",
      "        [ 0.1017],\n",
      "        [ 0.0458],\n",
      "        [-0.0472],\n",
      "        [ 0.0173],\n",
      "        [ 0.0415],\n",
      "        [ 0.1479],\n",
      "        [ 0.1450],\n",
      "        [ 0.0447],\n",
      "        [ 0.0345],\n",
      "        [ 0.0465],\n",
      "        [ 0.0769],\n",
      "        [ 0.1339],\n",
      "        [ 0.1834],\n",
      "        [ 0.3135],\n",
      "        [ 0.4326],\n",
      "        [ 0.4681],\n",
      "        [ 0.3613],\n",
      "        [ 0.3182],\n",
      "        [ 0.2465],\n",
      "        [ 0.4301],\n",
      "        [ 0.4585],\n",
      "        [ 0.4846],\n",
      "        [ 0.5252],\n",
      "        [ 0.5376],\n",
      "        [ 0.5913],\n",
      "        [ 0.6383],\n",
      "        [ 0.6053],\n",
      "        [ 0.4306],\n",
      "        [ 0.3273],\n",
      "        [ 0.4750],\n",
      "        [ 0.4523],\n",
      "        [ 0.5644],\n",
      "        [ 0.6116],\n",
      "        [ 0.5892],\n",
      "        [ 0.5097],\n",
      "        [ 0.5737],\n",
      "        [ 0.4387],\n",
      "        [ 0.3197],\n",
      "        [ 0.3412],\n",
      "        [ 0.3471],\n",
      "        [ 0.4481],\n",
      "        [ 0.2066],\n",
      "        [ 0.1396],\n",
      "        [ 0.0909],\n",
      "        [ 0.0363],\n",
      "        [-0.1328],\n",
      "        [-0.1751],\n",
      "        [-0.2017],\n",
      "        [-0.1647],\n",
      "        [-0.1244],\n",
      "        [-0.0664],\n",
      "        [-0.0492],\n",
      "        [-0.2499],\n",
      "        [-0.2504],\n",
      "        [-0.2795],\n",
      "        [-0.2401],\n",
      "        [-0.2133],\n",
      "        [-0.2434],\n",
      "        [-0.2309],\n",
      "        [-0.3332],\n",
      "        [-0.3398],\n",
      "        [-0.3819],\n",
      "        [-0.3549],\n",
      "        [-0.3077],\n",
      "        [-0.3831],\n",
      "        [-0.3949],\n",
      "        [-0.3404],\n",
      "        [-0.2447],\n",
      "        [-0.2385],\n",
      "        [-0.2501],\n",
      "        [-0.4041],\n",
      "        [-0.4634],\n",
      "        [-0.4757],\n",
      "        [-0.4883],\n",
      "        [-0.4211],\n",
      "        [-0.5282],\n",
      "        [-0.4316],\n",
      "        [-0.4200],\n",
      "        [-0.4078],\n",
      "        [-0.3869],\n",
      "        [-0.3471],\n",
      "        [-0.3277],\n",
      "        [-0.2309],\n",
      "        [-0.2843],\n",
      "        [-0.2434],\n",
      "        [-0.1472],\n",
      "        [-0.1965],\n",
      "        [-0.1897],\n",
      "        [-0.2371],\n",
      "        [-0.2076],\n",
      "        [-0.1002]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    seq_x, seq_y, seq_x_mark, seq_y_mark = batch\n",
    "    print(\"Input Sequence (seq_x):\", seq_x.shape)\n",
    "    print(\"Target Sequence (seq_y):\", seq_y.shape)\n",
    "    print(\"Input Time Markers (seq_x_mark):\", seq_x_mark.shape)\n",
    "    print(\"Target Time Markers (seq_y_mark):\", seq_y_mark.shape)\n",
    "    print(\"First Batch Input Data:\\n\", seq_x[0])  # Inspect the first item in the batch\n",
    "    print(\"First Batch Target Data:\\n\", seq_y[0])  # Inspect the first target in the batch\n",
    "    break  # Only inspect the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaa712d9-aba9-4312-9d04-9382a8f0e1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"NVDA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8af71807-f35a-4792-a98f-47cf7efb4416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8/21/2019</td>\n",
       "      <td>4.263250</td>\n",
       "      <td>4.336250</td>\n",
       "      <td>4.241500</td>\n",
       "      <td>4.280750</td>\n",
       "      <td>4.256181</td>\n",
       "      <td>427244000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8/22/2019</td>\n",
       "      <td>4.290500</td>\n",
       "      <td>4.333250</td>\n",
       "      <td>4.247500</td>\n",
       "      <td>4.287000</td>\n",
       "      <td>4.262396</td>\n",
       "      <td>303488000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8/23/2019</td>\n",
       "      <td>4.210000</td>\n",
       "      <td>4.264750</td>\n",
       "      <td>4.041000</td>\n",
       "      <td>4.061000</td>\n",
       "      <td>4.037692</td>\n",
       "      <td>568056000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8/26/2019</td>\n",
       "      <td>4.140250</td>\n",
       "      <td>4.164500</td>\n",
       "      <td>4.097750</td>\n",
       "      <td>4.136250</td>\n",
       "      <td>4.112510</td>\n",
       "      <td>318208000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8/27/2019</td>\n",
       "      <td>4.174750</td>\n",
       "      <td>4.177500</td>\n",
       "      <td>4.015500</td>\n",
       "      <td>4.045000</td>\n",
       "      <td>4.021784</td>\n",
       "      <td>290968000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>7/24/2024</td>\n",
       "      <td>119.169998</td>\n",
       "      <td>119.949997</td>\n",
       "      <td>113.440002</td>\n",
       "      <td>114.250000</td>\n",
       "      <td>114.250000</td>\n",
       "      <td>327776900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>7/25/2024</td>\n",
       "      <td>113.040001</td>\n",
       "      <td>116.629997</td>\n",
       "      <td>106.300003</td>\n",
       "      <td>112.279999</td>\n",
       "      <td>112.279999</td>\n",
       "      <td>460067000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>7/26/2024</td>\n",
       "      <td>116.190002</td>\n",
       "      <td>116.199997</td>\n",
       "      <td>111.580002</td>\n",
       "      <td>113.059998</td>\n",
       "      <td>113.059998</td>\n",
       "      <td>293399100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>7/29/2024</td>\n",
       "      <td>113.690002</td>\n",
       "      <td>116.279999</td>\n",
       "      <td>111.300003</td>\n",
       "      <td>111.589996</td>\n",
       "      <td>111.589996</td>\n",
       "      <td>248152100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>7/30/2024</td>\n",
       "      <td>111.519997</td>\n",
       "      <td>111.989998</td>\n",
       "      <td>102.540001</td>\n",
       "      <td>103.730003</td>\n",
       "      <td>103.730003</td>\n",
       "      <td>486833300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1243 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date        Open        High         Low       Close   Adj Close  \\\n",
       "0     8/21/2019    4.263250    4.336250    4.241500    4.280750    4.256181   \n",
       "1     8/22/2019    4.290500    4.333250    4.247500    4.287000    4.262396   \n",
       "2     8/23/2019    4.210000    4.264750    4.041000    4.061000    4.037692   \n",
       "3     8/26/2019    4.140250    4.164500    4.097750    4.136250    4.112510   \n",
       "4     8/27/2019    4.174750    4.177500    4.015500    4.045000    4.021784   \n",
       "...         ...         ...         ...         ...         ...         ...   \n",
       "1238  7/24/2024  119.169998  119.949997  113.440002  114.250000  114.250000   \n",
       "1239  7/25/2024  113.040001  116.629997  106.300003  112.279999  112.279999   \n",
       "1240  7/26/2024  116.190002  116.199997  111.580002  113.059998  113.059998   \n",
       "1241  7/29/2024  113.690002  116.279999  111.300003  111.589996  111.589996   \n",
       "1242  7/30/2024  111.519997  111.989998  102.540001  103.730003  103.730003   \n",
       "\n",
       "         Volume  \n",
       "0     427244000  \n",
       "1     303488000  \n",
       "2     568056000  \n",
       "3     318208000  \n",
       "4     290968000  \n",
       "...         ...  \n",
       "1238  327776900  \n",
       "1239  460067000  \n",
       "1240  293399100  \n",
       "1241  248152100  \n",
       "1242  486833300  \n",
       "\n",
       "[1243 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4ebf3e-886d-4eaf-ad9c-a6ee66e0d145",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
